{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b46e47ba-d6b6-4eea-9d03-e5f0e6b35280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268eb95b-51a6-4ae5-9460-b4f721744d15",
   "metadata": {},
   "source": [
    "### This notebook perform cropping images that contain \"Giraffe\",\"Elephant\", \"Grants Gazelle\". It will pick up classes \"Giraffe\",\"Elephant\", \"Grants Gazelle\" then crop those images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abd63b47-9de2-4e9d-826a-21cb97bd8079",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r crop/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "102171ba-a609-48ea-9295-fb77bdd14e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "imbalance_train=pd.read_csv(\"imbalance_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5efe8b19-ca29-4335-a1f6-25da1335281c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3688, 17)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imbalance_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9235258-3146-4dae-8018-bd494881ee4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_df=imbalance_train[imbalance_train['labelclass_name'].isin([\"Giraffe\",\"Elephant\", \"Grants Gazelle\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09a4e64c-9639-4774-ab0f-2fdedb3710e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 17)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8704953-cd5d-494d-a5c7-11e68cf6d726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _crop(df,x1,y1,x2,y2,name='1',dr1=''):\n",
    "    \"\"\"\n",
    "    df: dataframe that contain annotation\n",
    "    x1, y1: relative coordinates of top-left corner(on width and height of original image) of new cropped image\n",
    "    x2, y2: relative coordinates of bottom-right corner(on width and height of original image) of new cropped image\n",
    "    x1,y1,x2,y2 are between 0 and 1\n",
    "    \"\"\"\n",
    "    dr='/home/jovyan/lost+found/annotations/'\n",
    "    #filter objects in cropped region\n",
    "    df1=df[(df['x_c'] > x1*df['im_width']) \\\n",
    "           & (df['x_c'] <x2*df['im_width']) \\\n",
    "           & (df['y_c'] > y1*df['im_height']) \\\n",
    "           & (df['y_c'] < y2*df['im_height'])].copy()\n",
    "    \n",
    "    #crop images and update filepath\n",
    "    df1_path=np.unique(df1['filepath'])\n",
    "    for f in df1_path:\n",
    "        im_df=df1[df1['filepath']==f].copy()\n",
    "        w=np.unique(im_df['im_width'])\n",
    "        h=np.unique(im_df['im_height'])\n",
    "        im=Image.open(f)\n",
    "        im1=im.crop((int(x1*w),int(y1*h),int(x2*w),int(y2*h)))\n",
    "        im1.save(dr1+name+f.replace(\"/\",\"_\"))\n",
    "        df1.loc[df1['filepath']==f,'filepath'] = dr+dr1+ name + f.replace(\"/\",\"_\")\n",
    "     \n",
    "    #update object coordinates\n",
    "    df1.x_min=round(df1.x_min-x1*df1.im_width)\n",
    "    df1.x_max=round(df1.x_max-x1*df1.im_width)\n",
    "    df1.y_min=round(df1.y_min-y1*df1.im_height)\n",
    "    df1.y_max=round(df1.y_max-y1*df1.im_height)\n",
    "    \n",
    "    #update new size for cropped images\n",
    "    df1.im_width=round((x2-x1)*df1.im_width)\n",
    "    df1.im_height=round((y2-y1)*df1.im_height)\n",
    "    \n",
    "    #correct location of objects:\n",
    "    df1.loc[df1['x_min']<0,'x_min']=0 #ensure bounding boxes are within cropped images\n",
    "    df1.loc[df1['y_min']<0,'y_min']=0 #ensure bounding boxes are within cropped images\n",
    "    df1['x_max']=df1[['x_max','im_width']].min(axis=1) #ensure bounding boxes are within cropped images\n",
    "    df1['y_max']=df1[['y_max','im_height']].min(axis=1) #ensure bounding boxes are within cropped images\n",
    "    \n",
    "    #update centers of objects\n",
    "    df1.x_c=round(0.5*(df1.x_min+df1.x_max))\n",
    "    df1.y_c=round(0.5*(df1.y_min+df1.y_max))\n",
    "    df1.width=round((df1.x_max-df1.x_min)/df1.im_width,3)\n",
    "    df1.height=round((df1.y_max-df1.y_min)/df1.im_height,3)\n",
    "    \n",
    "    return df1.copy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87ef4e33-3378-4f4c-aa0f-1dd8f3fda41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Imbalance_crop=imbalance_train.copy()\n",
    "for i in range(0,8):\n",
    "    crop_i=_crop(im_df,i/20, 0, 1, 1,name=str(i),dr1=\"crop/\")\n",
    "    crop_j=_crop(im_df,0, 0, 1-1.2*(8-i)/20, 1,name=str(i+10),dr1=\"crop/\")\n",
    "    crop_ij=_crop(im_df,i/17,i/25 , 1, 1,name=str(i+20),dr1=\"crop/\")\n",
    "    crop_ji=_crop(im_df,0, 0, 1-(8-i)/20, 1-(8-i)/25,name=str(i+30),dr1=\"crop/\")\n",
    "    crop_ii=_crop(im_df,i/30,i/35 , 1-(8-i)/30, 1-(8-i)/35,name=str(i+40),dr1=\"crop/\")\n",
    "    crop_jj=_crop(im_df,i/20,i/20 , i/20+0.5, i/20+0.5,name=str(i+50),dr1=\"crop/\")\n",
    "    Imbalance_crop=Imbalance_crop.append([crop_i.copy(),crop_j.copy(),crop_ij.copy(),crop_ji.copy(),\n",
    "                                          crop_ii.copy(),crop_jj.copy()],ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baff420a-ab09-4e1e-818d-e47aea53b0fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5787, 17)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Imbalance_crop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8d12674-0b61-4c94-b24f-80f819f33959",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_count(dat):\n",
    "    #Count how many images for each type of class:\n",
    "    count={}\n",
    "    for lb in np.unique(dat['labelclass_name']):\n",
    "        df=dat[dat['labelclass_name']==lb]\n",
    "        count[lb]=len(np.unique(df['filepath']))\n",
    "\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b08975e6-ec5c-4f81-a4e6-e6eca6c9011c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Elephant': 373, 'Giraffe': 419, 'Grants Gazelle': 360, 'Wildebeest': 389}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_count(Imbalance_crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90f0b459-a50d-4653-9700-b80eae8271dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Imbalance_crop.to_csv(\"imbalance_crop.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e7b13115-3906-4a9b-b1aa-263726e0c842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/lost+found/annotations'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d927c32b-47e8-4859-a0ac-52d5e622fe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp '/home/jovyan/lost+found/annotations/imbalance_crop.csv' '/home/jovyan/lost+found/yolo3/train/imbalance_crop.csv'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
